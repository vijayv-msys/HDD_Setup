{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6f05455-8e1b-49fa-adad-ea2ed1cf6019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/07 01:58:40 WARN Utils: Your hostname, msys-virtual-machine resolves to a loopback address: 127.0.1.1; using 172.30.44.147 instead (on interface ens160)\n",
      "23/06/07 01:58:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/07 01:58:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('Model').enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f9853f-1ebd-4027-b276-0413a623a068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(path='file:///home/msys/code/dataset.csv',header=True,inferSchema=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61c61c4b-6963-49d9-85b1-bdda1dea82e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f5787f0-aafb-4b03-b7bf-42201efea18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "df=df.drop('_c0','date','unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e610e0ad-a42e-4873-a9c4-2888a908d28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'serial_number': 0,\n",
       " 'model': 0,\n",
       " 'capacity_bytes': 0,\n",
       " 'failure': 0,\n",
       " 'smart_1_normalized': 8,\n",
       " 'smart_1_raw': 8,\n",
       " 'smart_2_normalized': 6434,\n",
       " 'smart_2_raw': 6434,\n",
       " 'smart_3_normalized': 35,\n",
       " 'smart_3_raw': 35,\n",
       " 'smart_4_normalized': 35,\n",
       " 'smart_4_raw': 35,\n",
       " 'smart_5_normalized': 20,\n",
       " 'smart_5_raw': 20,\n",
       " 'smart_7_normalized': 35,\n",
       " 'smart_7_raw': 35,\n",
       " 'smart_8_normalized': 6434,\n",
       " 'smart_8_raw': 6434,\n",
       " 'smart_9_normalized': 4,\n",
       " 'smart_9_raw': 4,\n",
       " 'smart_10_normalized': 35,\n",
       " 'smart_10_raw': 35,\n",
       " 'smart_11_normalized': 7801,\n",
       " 'smart_11_raw': 7801,\n",
       " 'smart_12_normalized': 4,\n",
       " 'smart_12_raw': 4,\n",
       " 'smart_13_normalized': 7927,\n",
       " 'smart_13_raw': 7927,\n",
       " 'smart_15_normalized': 7929,\n",
       " 'smart_15_raw': 7929,\n",
       " 'smart_16_normalized': 7913,\n",
       " 'smart_16_raw': 7913,\n",
       " 'smart_17_normalized': 7913,\n",
       " 'smart_17_raw': 7913,\n",
       " 'smart_18_normalized': 7657,\n",
       " 'smart_18_raw': 7657,\n",
       " 'smart_22_normalized': 7805,\n",
       " 'smart_22_raw': 7805,\n",
       " 'smart_23_normalized': 7803,\n",
       " 'smart_23_raw': 7803,\n",
       " 'smart_24_normalized': 7803,\n",
       " 'smart_24_raw': 7803,\n",
       " 'smart_160_normalized': 7929,\n",
       " 'smart_160_raw': 7929,\n",
       " 'smart_161_normalized': 7929,\n",
       " 'smart_161_raw': 7929,\n",
       " 'smart_163_normalized': 7929,\n",
       " 'smart_163_raw': 7929,\n",
       " 'smart_164_normalized': 7929,\n",
       " 'smart_164_raw': 7929,\n",
       " 'smart_165_normalized': 7925,\n",
       " 'smart_165_raw': 7925,\n",
       " 'smart_166_normalized': 7925,\n",
       " 'smart_166_raw': 7925,\n",
       " 'smart_167_normalized': 7925,\n",
       " 'smart_167_raw': 7925,\n",
       " 'smart_168_normalized': 7909,\n",
       " 'smart_168_raw': 7909,\n",
       " 'smart_169_normalized': 7925,\n",
       " 'smart_169_raw': 7925,\n",
       " 'smart_170_normalized': 7908,\n",
       " 'smart_170_raw': 7908,\n",
       " 'smart_171_normalized': 7916,\n",
       " 'smart_171_raw': 7916,\n",
       " 'smart_172_normalized': 7916,\n",
       " 'smart_172_raw': 7916,\n",
       " 'smart_173_normalized': 7899,\n",
       " 'smart_173_raw': 7899,\n",
       " 'smart_174_normalized': 7899,\n",
       " 'smart_174_raw': 7899,\n",
       " 'smart_175_normalized': 7928,\n",
       " 'smart_175_raw': 7928,\n",
       " 'smart_176_normalized': 7929,\n",
       " 'smart_176_raw': 7929,\n",
       " 'smart_177_normalized': 7913,\n",
       " 'smart_177_raw': 7913,\n",
       " 'smart_178_normalized': 7929,\n",
       " 'smart_178_raw': 7929,\n",
       " 'smart_179_normalized': 7927,\n",
       " 'smart_179_raw': 7927,\n",
       " 'smart_180_normalized': 7918,\n",
       " 'smart_180_raw': 7918,\n",
       " 'smart_181_normalized': 7927,\n",
       " 'smart_181_raw': 7927,\n",
       " 'smart_182_normalized': 7927,\n",
       " 'smart_182_raw': 7927,\n",
       " 'smart_183_normalized': 2083,\n",
       " 'smart_183_raw': 2083,\n",
       " 'smart_184_normalized': 1864,\n",
       " 'smart_184_raw': 1864,\n",
       " 'smart_187_normalized': 1570,\n",
       " 'smart_187_raw': 1570,\n",
       " 'smart_188_normalized': 1579,\n",
       " 'smart_188_raw': 1579,\n",
       " 'smart_189_normalized': 1878,\n",
       " 'smart_189_raw': 1878,\n",
       " 'smart_190_normalized': 1583,\n",
       " 'smart_190_raw': 1583,\n",
       " 'smart_191_normalized': 1533,\n",
       " 'smart_191_raw': 1533,\n",
       " 'smart_192_normalized': 19,\n",
       " 'smart_192_raw': 19,\n",
       " 'smart_193_normalized': 110,\n",
       " 'smart_193_raw': 110,\n",
       " 'smart_194_normalized': 4,\n",
       " 'smart_194_raw': 4,\n",
       " 'smart_195_normalized': 6596,\n",
       " 'smart_195_raw': 6596,\n",
       " 'smart_196_normalized': 6372,\n",
       " 'smart_196_raw': 6372,\n",
       " 'smart_197_normalized': 29,\n",
       " 'smart_197_raw': 29,\n",
       " 'smart_198_normalized': 24,\n",
       " 'smart_198_raw': 24,\n",
       " 'smart_199_normalized': 20,\n",
       " 'smart_199_raw': 20,\n",
       " 'smart_200_normalized': 7492,\n",
       " 'smart_200_raw': 7492,\n",
       " 'smart_201_normalized': 7927,\n",
       " 'smart_201_raw': 7927,\n",
       " 'smart_202_normalized': 7918,\n",
       " 'smart_202_raw': 7918,\n",
       " 'smart_206_normalized': 7920,\n",
       " 'smart_206_raw': 7920,\n",
       " 'smart_210_normalized': 7920,\n",
       " 'smart_210_raw': 7920,\n",
       " 'smart_218_normalized': 7913,\n",
       " 'smart_218_raw': 7913,\n",
       " 'smart_220_normalized': 7688,\n",
       " 'smart_220_raw': 7688,\n",
       " 'smart_222_normalized': 7688,\n",
       " 'smart_222_raw': 7688,\n",
       " 'smart_223_normalized': 7610,\n",
       " 'smart_223_raw': 7610,\n",
       " 'smart_224_normalized': 7688,\n",
       " 'smart_224_raw': 7688,\n",
       " 'smart_225_normalized': 7854,\n",
       " 'smart_225_raw': 7854,\n",
       " 'smart_226_normalized': 7688,\n",
       " 'smart_226_raw': 7688,\n",
       " 'smart_230_normalized': 7925,\n",
       " 'smart_230_raw': 7925,\n",
       " 'smart_231_normalized': 7913,\n",
       " 'smart_231_raw': 7913,\n",
       " 'smart_232_normalized': 7909,\n",
       " 'smart_232_raw': 7909,\n",
       " 'smart_233_normalized': 7907,\n",
       " 'smart_233_raw': 7907,\n",
       " 'smart_234_normalized': 7922,\n",
       " 'smart_234_raw': 7922,\n",
       " 'smart_235_normalized': 7912,\n",
       " 'smart_235_raw': 7912,\n",
       " 'smart_240_normalized': 1330,\n",
       " 'smart_240_raw': 1330,\n",
       " 'smart_241_normalized': 1554,\n",
       " 'smart_241_raw': 1554,\n",
       " 'smart_242_normalized': 1554,\n",
       " 'smart_242_raw': 1554,\n",
       " 'smart_244_normalized': 7925,\n",
       " 'smart_244_raw': 7925,\n",
       " 'smart_245_normalized': 7927,\n",
       " 'smart_245_raw': 7927,\n",
       " 'smart_246_normalized': 7920,\n",
       " 'smart_246_raw': 7920,\n",
       " 'smart_247_normalized': 7920,\n",
       " 'smart_247_raw': 7920,\n",
       " 'smart_248_normalized': 7920,\n",
       " 'smart_248_raw': 7920,\n",
       " 'smart_250_normalized': 7929,\n",
       " 'smart_250_raw': 7929,\n",
       " 'smart_251_normalized': 7929,\n",
       " 'smart_251_raw': 7929,\n",
       " 'smart_252_normalized': 7929,\n",
       " 'smart_252_raw': 7929,\n",
       " 'smart_254_normalized': 7915,\n",
       " 'smart_254_raw': 7915,\n",
       " 'smart_255_normalized': 7929,\n",
       " 'smart_255_raw': 7929}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_counts = {column: df.filter(f\"`{column}` is null\").count() for column in df.columns}\n",
    "null_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e78c63b-adcd-4e9d-85ea-d6ce969220e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = df.fillna('null').select([col(c).cast(\"integer\").alias(c) for c in df.columns])\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f75368e-30c0-4f00-8a61-18c5f6a0bd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8a7f792-d44a-4346-9adc-447d47c3ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eca5ecc-05a5-4e7a-a96f-0ae548a94aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = {column: df.filter(f\"`{column}` is null\").count() for column in df.columns}\n",
    "#null_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4605801-f27c-4289-9bdd-6a77e3086b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['capacity_bytes',\n",
       " 'smart_1_normalized',\n",
       " 'smart_2_normalized',\n",
       " 'smart_2_raw',\n",
       " 'smart_3_normalized',\n",
       " 'smart_3_raw',\n",
       " 'smart_4_raw',\n",
       " 'smart_5_normalized',\n",
       " 'smart_5_raw',\n",
       " 'smart_7_normalized',\n",
       " 'smart_8_normalized',\n",
       " 'smart_8_raw',\n",
       " 'smart_9_normalized',\n",
       " 'smart_9_raw',\n",
       " 'smart_12_raw',\n",
       " 'smart_18_normalized',\n",
       " 'smart_22_normalized',\n",
       " 'smart_22_raw',\n",
       " 'smart_23_normalized',\n",
       " 'smart_24_normalized',\n",
       " 'smart_183_normalized',\n",
       " 'smart_184_normalized',\n",
       " 'smart_187_normalized',\n",
       " 'smart_187_raw',\n",
       " 'smart_188_normalized']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, ChiSqSelector\n",
    "from pyspark.ml.stat import ChiSquareTest\n",
    "\n",
    "feature_columns=df.drop('failure').columns\n",
    "\n",
    "# Assuming your label column is named 'failure'\n",
    "label_column = 'failure'\n",
    "\n",
    "# Assemble the feature columns into a vector\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')\n",
    "assembled_data = assembler.transform(df)\n",
    "\n",
    "# Compute chi-squared statistics for feature selection\n",
    "selector = ChiSquareTest.test(assembled_data, 'features', label_column)\n",
    "p_values = selector.select('pValues').first()[0]\n",
    "\n",
    "# Select the top-k features based on p-values\n",
    "k = 25  # Number of top features to select\n",
    "selected_features_indices = sorted(range(len(p_values)), key=lambda i: p_values[i])[:k]\n",
    "selected_feature_columns = [feature_columns[i] for i in selected_features_indices]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "selected_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "052a21b4-862f-4b19-a4cd-d3158df9a874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7929"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b79ca75a-fa10-4ccc-a46d-73e18fd45c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier, RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62277bbe-592b-40a6-a57b-c39125af44b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['capacity_bytes',\n",
       " 'smart_1_normalized',\n",
       " 'smart_2_normalized',\n",
       " 'smart_2_raw',\n",
       " 'smart_3_normalized',\n",
       " 'smart_3_raw',\n",
       " 'smart_4_raw',\n",
       " 'smart_5_normalized',\n",
       " 'smart_5_raw',\n",
       " 'smart_7_normalized',\n",
       " 'smart_8_normalized',\n",
       " 'smart_8_raw',\n",
       " 'smart_9_normalized',\n",
       " 'smart_9_raw',\n",
       " 'smart_12_raw',\n",
       " 'smart_18_normalized',\n",
       " 'smart_22_normalized',\n",
       " 'smart_22_raw',\n",
       " 'smart_23_normalized',\n",
       " 'smart_24_normalized',\n",
       " 'smart_183_normalized',\n",
       " 'smart_184_normalized',\n",
       " 'smart_187_normalized',\n",
       " 'smart_187_raw',\n",
       " 'smart_188_normalized',\n",
       " 'failure']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features =selected_feature_columns +['failure']\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a004f369-5b64-44b0-85d8-c106ce9f427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=selected_features, outputCol='features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d74fc324-1872-41ee-b5ed-52114a33d389",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembled_data = assembler.transform(df[selected_features])\n",
    "assembler.write().overwrite().save(\"file:///home/msys/code/assembled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6a566ce-65cf-4d5e-8628-911375d46d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = assembled_data.randomSplit([0.5, 0.5], seed=78)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5218145-a2ad-4175-b55c-30d69f84190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    GBTClassifier(labelCol='failure', featuresCol='features'),\n",
    "    RandomForestClassifier(labelCol='failure', featuresCol='features')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9783bce-c5da-473c-9e24-72aece67277e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GBTClassifier, AUC: 1.0\n",
      "Model: RandomForestClassifier, AUC: 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_auc = 0.0\n",
    "\n",
    "for model in models:\n",
    "    pipeline = Pipeline(stages=[model])\n",
    "    fitted_model = pipeline.fit(train_data)\n",
    "    predictions = fitted_model.transform(test_data)\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol='failure')\n",
    "    auc = evaluator.evaluate(predictions)\n",
    "    \n",
    "    print(f\"Model: {model.__class__.__name__}, AUC: {auc}\")\n",
    "    \n",
    "    if auc > best_auc:\n",
    "        best_auc = auc\n",
    "        best_model = fitted_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81ce9672-48e1-499a-a43d-5cffa8365f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.stages[0].write().overwrite().save(\"file:///home/msys/code/model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cce648cd-ecd1-4ec5-9677-d1e341c8e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassificationModel\n",
    "\n",
    "# Load the saved GBTClassifier model\n",
    "loaded_model = GBTClassificationModel.load(\"file:///home/msys/code/model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0d8482f-054e-4244-a2da-e74da2315a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------------------+--------------------+\n",
      "|failure|prediction|         probability|       rawPrediction|\n",
      "+-------+----------+--------------------+--------------------+\n",
      "|      1|       1.0|[0.04364652142729...|[-1.5435020027249...|\n",
      "|      1|       1.0|[0.04364652142729...|[-1.5435020027249...|\n",
      "|      1|       1.0|[0.04364652142729...|[-1.5435020027249...|\n",
      "|      0|       0.0|[0.95635347857270...|[1.54350200272499...|\n",
      "|      1|       1.0|[0.04364652142729...|[-1.5435020027249...|\n",
      "+-------+----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = loaded_model.transform(test_data)\n",
    "#print(predictions.show())\n",
    "# Display the predicted values\n",
    "final1=predictions.select( 'failure',  'prediction', 'probability','rawPrediction',)\n",
    "final1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bad17c1e-6d74-408a-aa4b-121176468289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /home/msys/.local/lib/python3.8/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /home/msys/.local/lib/python3.8/site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "420e495a-173f-41d7-94df-5f7a4ad656f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0 1.0 1.0 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------------------+--------------------+-----+\n",
      "|failure|prediction|    Confidence_Level|         probability|index|\n",
      "+-------+----------+--------------------+--------------------+-----+\n",
      "|      1|       1.0|[-1.5435020027249...|[0.04364652142729...|    0|\n",
      "|      1|       1.0|[-1.5435020027249...|[0.04364652142729...|    1|\n",
      "|      1|       1.0|[-1.5435020027249...|[0.04364652142729...|    2|\n",
      "|      0|       0.0|[1.54350200272499...|[0.95635347857270...|    3|\n",
      "|      1|       1.0|[-1.5435020027249...|[0.04364652142729...|    4|\n",
      "|      1|       1.0|[-1.5435020027249...|[0.04364652142729...|    5|\n",
      "|      0|       0.0|[1.54350200272499...|[0.95635347857270...|    6|\n",
      "|      1|       1.0|[-1.5435020027249...|[0.04364652142729...|    7|\n",
      "|      1|       1.0|[-1.5435020027249...|[0.04364652142729...|    8|\n",
      "|      0|       0.0|[1.54350200272499...|[0.95635347857270...|    9|\n",
      "|      1|       1.0|[-1.5435020027249...|[0.04364652142729...|   10|\n",
      "|      1|       1.0|[-1.5435020027249...|[0.04364652142729...|   11|\n",
      "|      1|       1.0|[-1.5435020027249...|[0.04364652142729...|   12|\n",
      "|      0|       0.0|[1.54350200272499...|[0.95635347857270...|   13|\n",
      "|      0|       0.0|[1.54350200272499...|[0.95635347857270...|   14|\n",
      "|      0|       0.0|[1.54350200272499...|[0.95635347857270...|   15|\n",
      "|      1|       1.0|[-1.5435020027249...|[0.04364652142729...|   16|\n",
      "|      1|       1.0|[-1.5435020027249...|[0.04364652142729...|   17|\n",
      "|      0|       0.0|[1.54350200272499...|[0.95635347857270...|   18|\n",
      "|      0|       0.0|[1.54350200272499...|[0.95635347857270...|   19|\n",
      "+-------+----------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>failure</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Confidence_Level</th>\n",
       "      <th>Active_Probability</th>\n",
       "      <th>Failure_Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>fail</td>\n",
       "      <td>Predicted_to_be_fail</td>\n",
       "      <td>-1.543502002724985</td>\n",
       "      <td>0.04364652142729305</td>\n",
       "      <td>0.9563534785727069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>fail</td>\n",
       "      <td>Predicted_to_be_fail</td>\n",
       "      <td>-1.543502002724985</td>\n",
       "      <td>0.04364652142729305</td>\n",
       "      <td>0.9563534785727069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>fail</td>\n",
       "      <td>Predicted_to_be_fail</td>\n",
       "      <td>-1.543502002724985</td>\n",
       "      <td>0.04364652142729305</td>\n",
       "      <td>0.9563534785727069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>fail</td>\n",
       "      <td>Predicted_to_be_fail</td>\n",
       "      <td>-1.543502002724985</td>\n",
       "      <td>0.04364652142729305</td>\n",
       "      <td>0.9563534785727069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>fail</td>\n",
       "      <td>Predicted_to_be_fail</td>\n",
       "      <td>-1.5435020027249848</td>\n",
       "      <td>0.04364652142729307</td>\n",
       "      <td>0.9563534785727069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>Active</td>\n",
       "      <td>Active</td>\n",
       "      <td>1.5435020027249933</td>\n",
       "      <td>0.9563534785727076</td>\n",
       "      <td>0.04364652142729242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3784</th>\n",
       "      <td>Active</td>\n",
       "      <td>Active</td>\n",
       "      <td>1.5435020027249933</td>\n",
       "      <td>0.9563534785727076</td>\n",
       "      <td>0.04364652142729242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>Active</td>\n",
       "      <td>Active</td>\n",
       "      <td>1.5435020027249933</td>\n",
       "      <td>0.9563534785727076</td>\n",
       "      <td>0.04364652142729242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774</th>\n",
       "      <td>Active</td>\n",
       "      <td>Active</td>\n",
       "      <td>1.5435020027249933</td>\n",
       "      <td>0.9563534785727076</td>\n",
       "      <td>0.04364652142729242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3926</th>\n",
       "      <td>Active</td>\n",
       "      <td>Active</td>\n",
       "      <td>1.5435020027249928</td>\n",
       "      <td>0.9563534785727076</td>\n",
       "      <td>0.04364652142729242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3927 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     failure            Prediction     Confidence_Level   Active_Probability  \\\n",
       "789     fail  Predicted_to_be_fail   -1.543502002724985  0.04364652142729305   \n",
       "2158    fail  Predicted_to_be_fail   -1.543502002724985  0.04364652142729305   \n",
       "1069    fail  Predicted_to_be_fail   -1.543502002724985  0.04364652142729305   \n",
       "2727    fail  Predicted_to_be_fail   -1.543502002724985  0.04364652142729305   \n",
       "3233    fail  Predicted_to_be_fail  -1.5435020027249848  0.04364652142729307   \n",
       "...      ...                   ...                  ...                  ...   \n",
       "3783  Active                Active   1.5435020027249933   0.9563534785727076   \n",
       "3784  Active                Active   1.5435020027249933   0.9563534785727076   \n",
       "3508  Active                Active   1.5435020027249933   0.9563534785727076   \n",
       "3774  Active                Active   1.5435020027249933   0.9563534785727076   \n",
       "3926  Active                Active   1.5435020027249928   0.9563534785727076   \n",
       "\n",
       "      Failure_Probability  \n",
       "789    0.9563534785727069  \n",
       "2158   0.9563534785727069  \n",
       "1069   0.9563534785727069  \n",
       "2727   0.9563534785727069  \n",
       "3233   0.9563534785727069  \n",
       "...                   ...  \n",
       "3783  0.04364652142729242  \n",
       "3784  0.04364652142729242  \n",
       "3508  0.04364652142729242  \n",
       "3774  0.04364652142729242  \n",
       "3926  0.04364652142729242  \n",
       "\n",
       "[3927 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 51100)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/msys/.local/lib/python3.8/site-packages/pyspark/accumulators.py\", line 281, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/msys/.local/lib/python3.8/site-packages/pyspark/accumulators.py\", line 253, in poll\n",
      "    if func():\n",
      "  File \"/home/msys/.local/lib/python3.8/site-packages/pyspark/accumulators.py\", line 257, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/msys/.local/lib/python3.8/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "from pyspark.sql.types import LongType\n",
    "from pyspark.sql import Row\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "# Make predicitons\n",
    "predictionAndTarget = loaded_model.transform(test_data).select(\"failure\", \"prediction\")\n",
    "predictionAndTargetNumpy = np.array((predictionAndTarget.collect()))\n",
    "acc = accuracy_score(predictionAndTargetNumpy[:,0], predictionAndTargetNumpy[:,1])\n",
    "f1 = f1_score(predictionAndTargetNumpy[:,0], predictionAndTargetNumpy[:,1])\n",
    "precision = precision_score(predictionAndTargetNumpy[:,0], predictionAndTargetNumpy[:,1])\n",
    "recall = recall_score(predictionAndTargetNumpy[:,0], predictionAndTargetNumpy[:,1])\n",
    "auc = roc_auc_score(predictionAndTargetNumpy[:,0], predictionAndTargetNumpy[:,1])\n",
    "print(acc,precision,recall,f1,auc) # GBTClassifier\n",
    "\n",
    "#STEP-13 predictions with validation data \n",
    "predictions = loaded_model.transform(test_data)\n",
    "final1=predictions.select('failure','prediction', 'rawPrediction', 'probability')\n",
    "\n",
    "def zipindexdf(df):\n",
    "    schema_new = df.schema.add(\"index\", LongType(), False)\n",
    "    return df.rdd.zipWithIndex().map(lambda l: list(l[0]) + [l[1]]).toDF(schema_new)\n",
    "\n",
    "#validation_serial_number_index = zipindexdf(validation_serial_number)\n",
    "final1_index = zipindexdf(final1)\n",
    "#final1_model_results = validation_serial_number_index.join(final1_index, \"index\", \"inner\")\n",
    "final1_model_results = final1_index.withColumnRenamed(\"rawPrediction\", \"Confidence_Level\")\n",
    "final1_model_results.show()\n",
    "\n",
    "# STEP-14 Download the predictions results\n",
    "pandasDF = final1_model_results.toPandas()\n",
    "pandasDF.failure.replace((0, 1), ('Active', 'fail'), inplace=True)\n",
    "pandasDF.prediction.replace((0, 1), ('Active', 'Predicted_to_be_fail'), inplace=True)\n",
    "pandasDF['Confidence_Level'] = pandasDF['Confidence_Level'].astype('str')\n",
    "pandasDF['probability'] = pandasDF['probability'].astype('str')\n",
    "Confidence_Level=pandasDF['Confidence_Level'].str.split(',', expand=True)\n",
    "pandasDF = pandasDF.join(Confidence_Level).drop(1, axis=1)\n",
    "pandasDF = pandasDF.drop('Confidence_Level', axis=1)\n",
    "pandasDF.rename(columns = {0:'Confidence_Level'}, inplace = True)\n",
    "probability1=pandasDF['probability'].str.split(',', expand=True)\n",
    "probability1.rename(columns = {0:'Active_Probability'}, inplace = True)\n",
    "probability1.rename(columns = {1:'Failure_Probability'}, inplace = True)\n",
    "pandasDF = pandasDF.join(probability1)\n",
    "pandasDF = pandasDF.drop(['probability'], axis=1)\n",
    "pandasDF = pandasDF.drop(['index'],axis=1)\n",
    "pandasDF.rename(columns = {'serial_number':'Serial_Number'}, inplace = True)\n",
    "pandasDF.rename(columns = {'model':'Model'}, inplace = True)\n",
    "pandasDF.rename(columns = {'label':'Actaul'}, inplace = True)\n",
    "pandasDF.rename(columns = {'prediction':'Prediction'}, inplace = True)\n",
    "pandasDF=pandasDF.replace('\\]','',regex=True).astype(str)\n",
    "pandasDF=pandasDF.replace('\\[','',regex=True).astype(str)\n",
    "pandasDF.sort_values(by=['Prediction'], inplace=True, ascending=False)\n",
    "pandasDF.sort_values(by=['Active_Probability'], inplace=True)\n",
    "# download csv file \n",
    "\n",
    "pandasDF.to_csv(r'file:///home/msys/code/prediction_results.csv')\n",
    "# download excel file \n",
    "\n",
    "pandasDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34752843-78e8-491b-8ced-708e8168d0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e00afa-9531-49bb-b839-09c17c286986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a76cd-67ec-4f12-a0e7-5b0b49d36867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c870a7-9f93-4fbc-a988-fe95993d1691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5e7ee9-3319-4d5b-b9c1-b957e477eed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389c1b72-9971-42c4-9310-130d69c90e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33abb42a-7a85-4b3f-a969-a2775e2add9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7629233511586453\n",
      "+-------+----------+-----+\n",
      "|failure|prediction|count|\n",
      "+-------+----------+-----+\n",
      "|      0|       0.0| 2870|\n",
      "|      0|       1.0|  622|\n",
      "|      1|       0.0|  309|\n",
      "|      1|       1.0|  126|\n",
      "+-------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Create an evaluator for multi-class classification\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='failure', predictionCol='prediction', metricName='accuracy')\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Create a confusion matrix\n",
    "confusion_matrix = predictions.groupBy('failure', 'prediction').count().orderBy('failure', 'prediction')\n",
    "confusion_matrix.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99a7c2ac-8266-4af8-b808-bd40f9472caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "result = test_data['smart_3_raw', 'smart_2_raw']\n",
    "res1=predictions.select('failure', 'prediction')\n",
    "# Add a unique identifier column to each DataFrame\n",
    "df1 = result.withColumn('id', monotonically_increasing_id())\n",
    "df2 = res1.withColumn('id', monotonically_increasing_id())\n",
    "\n",
    "# Perform an inner join on the 'id' column\n",
    "concatenated_df = df1.join(df2, 'id', 'inner').drop('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4459bc1f-85d8-42a4-80f1-927bc6bf797c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-------+----------+\n",
      "|smart_3_raw|smart_2_raw|failure|prediction|\n",
      "+-----------+-----------+-------+----------+\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      0|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      0|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      0|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      0|       0.0|\n",
      "|          0|          0|      0|       0.0|\n",
      "|          0|          0|      0|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      0|       0.0|\n",
      "|          0|          0|      0|       0.0|\n",
      "+-----------+-----------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "concatenated_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc705807-63ff-4a7d-826c-ff8c60654d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-------+----------+\n",
      "|smart_3_raw|smart_2_raw|failure|prediction|\n",
      "+-----------+-----------+-------+----------+\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      0|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      0|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      0|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      0|       0.0|\n",
      "|          0|          0|      0|       0.0|\n",
      "|          0|          0|      0|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      1|       0.0|\n",
      "|          0|          0|      0|       0.0|\n",
      "|          0|          0|      0|       0.0|\n",
      "+-----------+-----------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "concatenated_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61f68c6f-9754-474b-ba08-134e7cb28104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smart_3_raw</th>\n",
       "      <th>smart_2_raw</th>\n",
       "      <th>failure</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>1316</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>1266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>1275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>1300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3926</th>\n",
       "      <td>1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3927 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      smart_3_raw  smart_2_raw  failure  prediction\n",
       "0               0            0        1         0.0\n",
       "1               0            0        1         0.0\n",
       "2               0            0        1         0.0\n",
       "3               0            0        0         0.0\n",
       "4               0            0        1         0.0\n",
       "...           ...          ...      ...         ...\n",
       "3922         1316            0        0         0.0\n",
       "3923         1266            0        0         0.0\n",
       "3924         1275            0        0         0.0\n",
       "3925         1300            0        0         0.0\n",
       "3926         1250            0        0         0.0\n",
       "\n",
       "[3927 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf = concatenated_df.toPandas()\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3522e62-5222-43ef-a5ac-cdff014c8fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.8/dist-packages (2.0.15)\n",
      "Requirement already satisfied: greenlet!=0.4.17; platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\"))))) in /usr/local/lib/python3.8/dist-packages (from sqlalchemy) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/msys/.local/lib/python3.8/site-packages (from sqlalchemy) (4.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be25180b-776c-4d26-a15e-9e27a5a3eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\"\"\"\n",
    "db_username = 'postgres'\n",
    "db_password = 'Vijay2590'\n",
    "db_host = 'postgresql.cf4zunotlmzs.eu-north-1.rds.amazonaws.com'\n",
    "db_port = '5432'\n",
    "db_name = 'test'\n",
    "\n",
    "\n",
    "connection_string = f'postgresql://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}'\n",
    "engine = create_engine(connection_string)\n",
    "table_name = 'lenovo'  \n",
    "# dt.to_sql('employees', engine)\n",
    "\n",
    "pdf.to_sql(table_name, engine, if_exists='append', index=False)\n",
    "\n",
    "\"\"\"\n",
    "# Connect to the PostgreSQL database\n",
    "engine = create_engine('postgresql://postgres:1234@localhost/lenovo')\n",
    "# Convert DataFrame to a PostgreSQL table\n",
    "table_name = 'lenovo_result'\n",
    "pdf.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "\n",
    "# Optional: Close the database connection\n",
    "engine.dispose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f6b9153-ac7e-49f9-a864-0c2efe138d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smart_3_raw</th>\n",
       "      <th>smart_2_raw</th>\n",
       "      <th>failure</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>1316</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>1266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>1275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>1300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3926</th>\n",
       "      <td>1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3927 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      smart_3_raw  smart_2_raw  failure  prediction\n",
       "0               0            0        1         0.0\n",
       "1               0            0        1         0.0\n",
       "2               0            0        1         0.0\n",
       "3               0            0        0         0.0\n",
       "4               0            0        1         0.0\n",
       "...           ...          ...      ...         ...\n",
       "3922         1316            0        0         0.0\n",
       "3923         1266            0        0         0.0\n",
       "3924         1275            0        0         0.0\n",
       "3925         1300            0        0         0.0\n",
       "3926         1250            0        0         0.0\n",
       "\n",
       "[3927 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Connect to the PostgreSQL database\n",
    "engine = create_engine('postgresql://postgres:1234@localhost/lenovo')\n",
    "\n",
    "# Specify the query to retrieve data\n",
    "query = 'SELECT * FROM lenovo_result'\n",
    "\n",
    "# Read data from PostgreSQL into a DataFrame\n",
    "result = pd.read_sql(query, engine)\n",
    "\n",
    "# Optional: Close the database connection\n",
    "engine.dispose()\n",
    "\n",
    "# Display the DataFrame\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f6155ec-eaf9-433d-a154-9cd7ccf5ae21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../MSys_Demo_App/staticFile/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da08577-72ec-4dbd-9e9b-0e3c4bd8ae3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea25a0f7-7fd3-4f8a-84e7-fd36f2e3bcef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7358f4b7-5853-48cd-ab5f-f290cdb3c67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5c3193-f202-403d-be98-bc625f7f2afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7608b7bf-edae-480c-855e-ffa51bc63b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b036eb1-6a5b-47ec-b8fb-e0775fad16a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8c0704-9334-4b29-ba9b-06a82b962e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afae319-0a58-4e20-8045-026273020f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564884aa-e1c0-4d00-8f99-05d7ed531b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
